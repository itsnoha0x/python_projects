import streamlit as st
import pandas as pd
import numpy as np
import pickle
import json
import matplotlib.pyplot as plt
import seaborn as sns

# --------------------------------------------------------
# Chargement des mod√®les
# --------------------------------------------------------
@st.cache_resource
def load_all():
    with open("models/metrics.json", "r") as f:
        metrics = json.load(f)

    scaler = pickle.load(open("models/scaler.pkl", "rb"))

    models = {
        "Logistic Regression": pickle.load(open("models/Logistic_Regression.pkl", "rb")),
        "KNN": pickle.load(open("models/KNN.pkl", "rb")),
        "Decision Tree": pickle.load(open("models/Decision_Tree.pkl", "rb")),
        "Random Forest": pickle.load(open("models/Random_Forest.pkl", "rb"))
    }

    # For evaluation
    test = pd.read_csv("KDDTest+.txt", header=None)
    # numerical features only
    selected = [
        0,4,5,22,23,24,26,28,31,32
    ]
    X_test = test[selected]
    y_test = (test[41].str.strip().str.lower() != "normal").astype(int)

    X_test = scaler.transform(X_test)

    return models, scaler, metrics, X_test, y_test

models, scaler, metrics, X_test, y_test = load_all()

# --------------------------------------------------------
# Interface
# --------------------------------------------------------
st.title("D√©tection d‚Äôintrusions ‚Äì NSL-KDD")

mode = st.sidebar.selectbox(
    "Choisir mode",
    ["√âvaluation des mod√®les", "Entr√©e manuelle", "Upload CSV", "Explications"]
)

# --------------------------------------------------------
# Page 1 : √âvaluation des mod√®les
# --------------------------------------------------------
if mode == "√âvaluation des mod√®les":
    st.header("√âvaluation des mod√®les")

    options = list(models.keys()) + ["Comparaison globale"]
    chosen = st.selectbox("Choisir un mod√®le", options)

    # ============================
    # CAS 1 : √âvaluation d‚Äôun mod√®le unique
    # ============================
    if chosen != "Comparaison globale":
        st.subheader(f"M√©triques pour : {chosen}")

        m = metrics[chosen]

        st.write(f"Accuracy : {m['accuracy']:.4f}")
        st.write(f"Precision : {m['precision']:.4f}")
        st.write(f"Recall : {m['recall']:.4f}")
        st.write(f"F1-Score : {m['f1']:.4f}")

        # Matrice de confusion
        st.subheader("Matrice de Confusion")
        cm = np.array(m["confusion_matrix"])

        fig, ax = plt.subplots(figsize=(4, 3))
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False, ax=ax)
        ax.set_xlabel("Pr√©dit")
        ax.set_ylabel("R√©el")
        st.pyplot(fig)

    # ============================
    # CAS 2 : Comparaison globale des 4 mod√®les
    # ============================
    else:
        st.subheader("Comparaison des 4 mod√®les")

        rows = []
        for name in models.keys():
            m = metrics[name]
            rows.append({
                "Mod√®le": name,
                "Accuracy": float(m["accuracy"]),
                "Precision": float(m["precision"]),
                "Recall": float(m["recall"]),
                "F1-score": float(m["f1"])
            })

        df_compare = pd.DataFrame(rows)

        # Affichage format√© (format appliqu√© uniquement aux colonnes num√©riques)
        st.dataframe(
            df_compare.style.format({
                "Accuracy": "{:.4f}",
                "Precision": "{:.4f}",
                "Recall": "{:.4f}",
                "F1-score": "{:.4f}"
            })
        )

        # Trouver le meilleur mod√®le selon le F1-score
        best = df_compare.loc[df_compare["F1-score"].idxmax()]

        st.subheader("Conclusion")
        st.write(f"""
Le mod√®le le plus performant est : **{best['Mod√®le']}**

Il obtient un F1-score de **{best['F1-score']:.4f}**,  
ce qui indique qu‚Äôil fournit le meilleur √©quilibre entre :

- pr√©cision (qualit√© des d√©tections)
- rappel (capacit√© √† ne pas rater les attaques)

üëâ C‚Äôest donc le mod√®le recommand√© pour une d√©tection robuste des intrusions.
""")


# --------------------------------------------------------
# Page 2 : Entr√©e manuelle
# --------------------------------------------------------
elif mode == "Entr√©e manuelle":
    st.header("Entr√©e manuelle des caract√©ristiques")

    features = ["duration","src_bytes","dst_bytes","count","srv_count",
                "serror_rate","rerror_rate","same_srv_rate",
                "dst_host_count","dst_host_srv_count"]

    values = []

    for f in features:
        val = st.number_input(f, min_value=0.0, value=1.0)
        values.append(val)

    if st.button("Pr√©dire"):
        X = np.array(values).reshape(1,-1)
        X = scaler.transform(X)

        model = models["Random Forest"]
        pred = model.predict(X)[0]

        if pred == 1:
            st.error("Intrusion d√©tect√©e")
        else:
            st.success("Trafic normal")

# --------------------------------------------------------
# Page 3 : Upload CSV
# --------------------------------------------------------
elif mode == "Upload CSV":
    st.header("Upload d‚Äôun fichier CSV")

    file = st.file_uploader("Choisir un fichier CSV")

    if file:
        df = pd.read_csv(file)

        X = df.values
        X = scaler.transform(X)

        model = models["Random Forest"]
        preds = model.predict(X)

        # Affichage ligne par ligne
        pred_df = pd.DataFrame({"Prediction": preds})
        st.subheader("Pr√©dictions ligne par ligne")
        st.write(pred_df)

        # -----------------------------
        #  ANALYSE GLOBALE DU FICHIER
        # -----------------------------
        total = len(preds)
        attacks = np.sum(preds == 1)
        normals = np.sum(preds == 0)

        st.subheader("Analyse globale du fichier")

        st.write(f"- Nombre total de lignes : **{total}**")
        st.write(f"- Trafic normal : **{normals}**")
        st.write(f"- Attaques d√©tect√©es : **{attacks}**")

        # Conclusion globale
        st.subheader("Conclusion")

        if attacks == 0:
            st.success("Le fichier est probablement **NORMAL** (aucune attaque d√©tect√©e).")
        elif attacks < total * 0.3:
            st.warning("Le fichier contient quelques anomalies ‚Üí activit√© **suspecte**.")
        else:
            st.error("Le fichier est probablement **MALVEILLANT** (forte pr√©sence d‚Äôattaques).")


# --------------------------------------------------------
# Page 4 : Explications
# --------------------------------------------------------
elif mode == "Explications":
    st.header("üìò Explications du projet")

    st.write("""
Ce projet utilise le dataset **NSL-KDD**, un ensemble de donn√©es de r√©f√©rence en cybers√©curit√©,
pour entra√Æner quatre algorithmes de Machine Learning destin√©s √† la d√©tection d'intrusions. üîê

---

## 1. R√©gression Logistique ‚öôÔ∏è
La r√©gression logistique est un **mod√®le lin√©aire de classification binaire**.
Elle estime la probabilit√© qu‚Äôun trafic soit normal ou malveillant √† partir des caract√©ristiques r√©seau.

- Produit une probabilit√© entre 0 et 1  
- Bas√©e sur la fonction sigmo√Øde  
- Rapide, stable et efficace sur des donn√©es structur√©es  
- Interpr√©tation simple

---

## 2. KNN ‚Äî K-Nearest Neighbors ü§ù
KNN classe un nouvel √©chantillon en regardant ses **K voisins les plus similaires** dans le dataset.

- Pas d‚Äôapprentissage direct (lazy learning)  
- Repose sur la distance ‚Üí importance de la standardisation  
- Tr√®s intuitif  
- Performant lorsque les donn√©es sont bien distribu√©es

---

## 3. Arbre de D√©cision üå≥
L‚Äôarbre de d√©cision construit un ensemble de **r√®gles conditionnelles** sous forme de branches.

- Tr√®s facile √† interpr√©ter  
- Capture naturellement des relations non lin√©aires  
- Peut sur-apprendre si non r√©gul√©  
- Fonctionne bien sur des jeux de donn√©es tabulaires

---

## 4. Random Forest üå≤üå≤
Random Forest est un ensemble de plusieurs arbres de d√©cision entra√Æn√©s de fa√ßon ind√©pendante.

- R√©duit fortement le sur-apprentissage  
- Plus stable qu‚Äôun seul arbre  
- G√®re bien les donn√©es bruit√©es  
- Tr√®s utilis√© en d√©tection d‚Äôanomalies

---

## Standardisation des donn√©es (Normalization) üìè
Nous utilisons `StandardScaler` avant l‚Äôentra√Ænement :

- moyenne = 0  
- √©cart-type = 1  
- met toutes les variables sur la m√™me √©chelle  

Cela am√©liore la stabilit√© du mod√®le et est **essentiel** pour KNN et utile pour les autres algorithmes.

---

## Structure de l‚Äôapplication üñ•Ô∏è
L‚Äôapplication propose :

- Une page d‚Äô**√©valuation des mod√®les**  
- Une page d‚Äô**entr√©e manuelle**  
- Une page d‚Äô**upload CSV**  
- Une page d‚Äô**explications p√©dagogiques**

Elle permet ainsi de tester, comparer et utiliser un syst√®me d‚Äôapprentissage automatique
pour la d√©tection d‚Äôintrusions r√©seau.
""")
